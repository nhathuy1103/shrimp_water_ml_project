from typing import Dict, Any, Optional, List
import json
import re
import random

from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from src.llms.openai_llm import OpenAILM

def _norm_text(s: str) -> str:
    return (s or "").strip().lower()

def _has_any_water_data(w: Dict[str, Any]) -> bool:
    keys = ["NHIET_DO", "PH", "DO", "NO2", "NH4", "DO_MAN", "DO_TRONG", "PO43", "NO3", "COD", "DO_KIEM"]
    return any((k in w) and (w.get(k) not in [None, "", "None"]) for k in keys)

def _is_greeting(text: str) -> bool:
    t = _norm_text(text)
    prefixes = ["hi", "hii", "hello", "helo", "hey", "ch√†o", "chao", "xin ch√†o", "xin chao", "alo", "a l√¥"]
    return any(t == p or t.startswith(p + " ") for p in prefixes)

def _is_analysis_only(text: str) -> bool:
    t = _norm_text(text)
    keywords = [
        "ph√¢n t√≠ch", "phan tich", "ƒë√°nh gi√°", "danh gia", "nh·∫≠n x√©t", "nhan xet",
        "hi·ªán tr·∫°ng", "hien trang", "t√¨nh tr·∫°ng", "tinh trang",
        "k·∫øt qu·∫£", "ket qua", "ƒëang nh∆∞ th·∫ø n√†o", "dang nhu the nao", "ph√¢n lo·∫°i", "phan loai", "review",
        "coi gi√∫p", "coi dum", "coi sao", "coi th·ª≠", "coi thu"
    ]
    return any(k in t for k in keywords)

def _is_advice(text: str) -> bool:
    t = _norm_text(text)
    keywords = [
        "t∆∞ v·∫•n", "tu van", "x·ª≠ l√Ω", "xu ly", "gi·∫£i ph√°p", "giai phap", "khuy·∫øn ngh·ªã", "khuyen nghi",
        "n√™n l√†m", "nen lam", "c·∫£i thi·ªán", "cai thien", "h∆∞·ªõng d·∫´n", "huong dan",
        "k·∫ø ho·∫°ch", "ke hoach", "l√†m sao", "lam sao", "c√°ch", "cach", "ph·∫£i l√†m g√¨", "phai lam gi",
        "gi√∫p", "giup", "c·ª©u", "cuu"
    ]
    return any(k in t for k in keywords)

def _is_symptom_question(text: str) -> bool:
    t = _norm_text(text)
    keywords = [
        "d·∫•u hi·ªáu", "dau hieu", "tri·ªáu ch·ª©ng", "trieu chung",
        "b∆°i", "boi", "b·ªè ƒÉn", "bo an", "ƒëen mang", "den mang", "ƒë·ª©t r√¢u", "dut rau",
        "m·ªÅm v·ªè", "mem vo", "ƒë·ªè th√¢n", "do than", "l·ªù ƒë·ªù", "lo do", "n·ªïi ƒë·∫ßu", "noi dau",
        "ch·∫øt", "chet", "ƒë·ªëm tr·∫Øng", "dom trang", "gan t·ª•y", "gan tuy", "ph√¢n tr·∫Øng", "phan trang",
        "r·ª•ng r√¢u", "rung rau", "r·ª•ng ƒëu√¥i", "rung duoi", "ƒë√≥ng rong", "dong rong", "ƒë√≥ng nh·ªõt", "dong nhot"
    ]
    return ("t√¥m" in t or "tom" in t) and any(k in t for k in keywords)

def _is_smalltalk_or_meta(text: str) -> bool:
    t = _norm_text(text)
    keys = ["b·∫°n l√† ai", "ban la ai", "gi·ªõi thi·ªáu", "gioi thieu", "help", "gi√∫p t√¥i", "giup toi", "h∆∞·ªõng d·∫´n d√πng", "huong dan dung"]
    return any(k in t for k in keys)

def _rule_intent(text: str) -> str:
    t = _norm_text(text)
    if not t:
        return "unknown"
    if _is_greeting(t):
        return "greet"
    if _is_symptom_question(t):
        return "symptom"
    if _is_smalltalk_or_meta(t):
        return "meta"
    a = _is_analysis_only(t)
    b = _is_advice(t)
    if a and not b:
        return "analysis"
    if b and not a:
        return "advice"
    if a and b:
        return "ambiguous"
    return "unknown"

def _risk_to_priority(pred: Dict[str, Any]) -> str:
    t1 = _norm_text((pred or {}).get("task1_text", ""))
    t3 = _norm_text((pred or {}).get("task3_text", ""))
    if "nguy" in t1 or "kh√¥ng ƒë·∫°t" in t3:
        return "P1"
    return "P2"

def _render_compact(water_data: Dict[str, Any], prediction: Dict[str, Any]) -> str:
    vib_text = prediction.get("task1_text", "Kh√¥ng c√≥")
    vib_est = prediction.get("task2_vibrio_est", "Kh√¥ng c√≥")
    env_text = prediction.get("task3_text", "Kh√¥ng c√≥")
    algae_text = prediction.get("task4_text", "Kh√¥ng c√≥")
    priority = _risk_to_priority(prediction)
    lines = [
        "D·ªÆ LI·ªÜU AO (t√≥m t·∫Øt)",
        f"- ƒêi·ªÉm: {water_data.get('DIEM_QUAN_TRAC')} | X√£/Huy·ªán: {water_data.get('XA')}/{water_data.get('HUYEN')}",
        f"- Nhi·ªát ƒë·ªô: {water_data.get('NHIET_DO')} | pH: {water_data.get('PH')} | DO: {water_data.get('DO')}",
        f"- ƒê·ªô m·∫∑n: {water_data.get('DO_MAN')} | ƒê·ªô trong: {water_data.get('DO_TRONG')} | Ki·ªÅm: {water_data.get('DO_KIEM')}",
        f"- NO2: {water_data.get('NO2')} | NO3: {water_data.get('NO3')} | NH4: {water_data.get('NH4')} | PO43: {water_data.get('PO43')} | COD: {water_data.get('COD')}",
        "",
        "K·∫æT QU·∫¢ M√î H√åNH (4 TASK)",
        f"- Vibrio: {vib_text}",
        f"- Vibrio ∆∞·ªõc l∆∞·ª£ng: ~{vib_est} CFU/ml",
        f"- M√¥i tr∆∞·ªùng: {env_text}",
        f"- T·∫£o th·ª©c ƒÉn: {algae_text}",
        f"- M·ª©c ∆∞u ti√™n: {priority}",
    ]
    return "\n".join([x for x in lines if x is not None]).strip()

def _localize_text(text: str) -> str:
    if not text:
        return ""
    text = text.replace("B·∫°n", "M√¨nh").replace("b·∫°n", "m√¨nh")
    text = text.replace("T√¥i", "Em").replace("t√¥i", "em")
    text = re.sub(r"\bkh√¥ng\b", "h√¥ng", text, flags=re.IGNORECASE)
    text = re.sub(r"\bnhanh\b", "l·∫π", text, flags=re.IGNORECASE)
    text = re.sub(r"\bnghi√™m tr·ªçng\b", "cƒÉng", text, flags=re.IGNORECASE)
    return text.strip()

def _pick(*arr: str) -> str:
    return random.choice([a for a in arr if a])

class ShrimpAgent:
    def __init__(self, vectordb=None, llm: Optional[ChatOpenAI] = None):
        self.llm = llm or OpenAILM(model_name="gpt-4.1-mini", temperature=0.15).get_llm()
        self.qa_chain = None
        if vectordb is not None:
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                retriever=vectordb.as_retriever(search_kwargs={"k": 4}),
                chain_type="stuff",
            )

    def _llm_intent(self, question: str, has_data: bool, has_pred: bool) -> str:
        sys = """
B·∫°n l√† b·ªô ph√¢n lo·∫°i √Ω ƒë·ªãnh h·ªôi tho·∫°i cho chatbot nu√¥i t√¥m (mi·ªÅn T√¢y).
Ch·ªâ tr·∫£ v·ªÅ JSON 1 d√≤ng, kh√¥ng th√™m ch·ªØ kh√°c.
C√°c nh√£n:
- greet
- analysis (ph√¢n t√≠ch hi·ªán tr·∫°ng n∆∞·ªõc, kh√¥ng gi·∫£i ph√°p)
- advice (t∆∞ v·∫•n x·ª≠ l√Ω theo n∆∞·ªõc/ao)
- symptom (d·∫•u hi·ªáu t√¥m b·∫•t th∆∞·ªùng/b·ªánh)
- knowledge (ki·∫øn th·ª©c chung: t·∫£o, pH, DO, Vibrio... kh√¥ng c·∫ßn d·ªØ li·ªáu)
- meta (h·ªèi c√°ch d√πng/gi·ªõi thi·ªáu bot)
""".strip()

        usr = json.dumps({
            "question": question,
            "has_water_data": has_data,
            "has_prediction": has_pred
        }, ensure_ascii=False)

        out = self.llm.invoke([{"role": "system", "content": sys}, {"role": "user", "content": usr}]).content or ""
        out = out.strip()
        try:
            j = json.loads(out)
            it = _norm_text(j.get("intent", ""))
            allowed = {"greet", "analysis", "advice", "symptom", "knowledge", "meta"}
            return it if it in allowed else "knowledge"
        except Exception:
            return "knowledge"

    def answer(self, question: str, water_data: Optional[Dict[str, Any]] = None, prediction: Optional[Dict[str, Any]] = None) -> str:
        water_data = water_data or {}
        prediction = prediction or {}
        has_data = _has_any_water_data(water_data)
        has_pred = bool(prediction)

        it = _rule_intent(question)
        if it in {"unknown", "ambiguous"}:
            it = self._llm_intent(question, has_data, has_pred)

        if it == "greet":
            return _pick(
                "D·∫° ch√†o m√¨nh üëã M√¨nh mu·ªën em **ph√¢n t√≠ch n∆∞·ªõc**, **t∆∞ v·∫•n x·ª≠ l√Ω**, hay **h·ªèi d·∫•u hi·ªáu t√¥m** n√®?",
                "Ch√†o b√† con üëã M√¨nh h·ªèi em ki·ªÉu n√†o: **ph√¢n t√≠ch**, **t∆∞ v·∫•n**, hay **d·∫•u hi·ªáu t√¥m** nghen?"
            )

        if it == "meta":
            return _pick(
                "D·∫° em h·ªó tr·ª£ 3 ki·ªÉu: **ph√¢n t√≠ch n∆∞·ªõc** (kh√¥ng gi·∫£i ph√°p), **t∆∞ v·∫•n x·ª≠ l√Ω**, v√† **h·ªèi d·∫•u hi·ªáu t√¥m b·∫•t th∆∞·ªùng**. M√¨nh c·ª© h·ªèi t·ª± nhi√™n nghen.",
                "M√¨nh c·ª© nh·∫≠p s·ªë n∆∞·ªõc r·ªìi b·∫•m **D·ª± ƒëo√°n** ƒë·ªÉ em coi theo m√¥ h√¨nh. C√≤n h·ªèi d·∫•u hi·ªáu t√¥m/b·ªánh th√¨ h·ªèi tr·ª±c ti·∫øp c≈©ng ƒë∆∞·ª£c."
            )

        if it in {"analysis", "advice"} and (not has_data or not has_pred):
            if it == "analysis":
                return "D·∫° mu·ªën **ph√¢n t√≠ch n∆∞·ªõc** th√¨ m√¨nh nh·∫≠p s·ªë li·ªáu r·ªìi b·∫•m **D·ª± ƒëo√°n** tr∆∞·ªõc nghen, ƒë·ªÉ em coi ƒë√∫ng theo ao m√¨nh."
            return "D·∫° mu·ªën **t∆∞ v·∫•n x·ª≠ l√Ω theo ao** th√¨ m√¨nh nh·∫≠p s·ªë li·ªáu r·ªìi b·∫•m **D·ª± ƒëo√°n** tr∆∞·ªõc nghen. C√≤n n·∫øu h·ªèi **ki·∫øn th·ª©c chung** th√¨ m√¨nh h·ªèi lu√¥n c≈©ng ƒë∆∞·ª£c."

        if it == "symptom":
            system = """
B·∫°n l√† tr·ª£ l√Ω cho ng∆∞·ªùi nu√¥i t√¥m qu·∫£ng canh ·ªü C√† Mau, n√≥i ki·ªÉu mi·ªÅn T√¢y, d·ªÖ hi·ªÉu.
B·∫Øt bu·ªôc:
- T·∫≠p trung ƒë√∫ng d·∫•u hi·ªáu t√¥m/b·ªánh, kh√¥ng t·ª± chuy·ªÉn sang ph√¢n t√≠ch n∆∞·ªõc n·∫øu ng∆∞·ªùi d√πng kh√¥ng ƒë∆∞a s·ªë.
- Tr·∫£ l·ªùi theo khung 4 m·ª•c.
- Kh√¥ng h∆∞·ªõng d·∫´n d√πng kh√°ng sinh/h√≥a ch·∫•t theo li·ªÅu.
- N·∫øu kh·∫©n (t√¥m ch·∫øt nhanh/n·ªïi ƒë·∫ßu nhi·ªÅu) ph·∫£i c·∫£nh b√°o v√† khuy√™n li√™n h·ªá c√°n b·ªô ƒë·ªãa ph∆∞∆°ng.
""".strip()
            user = f"""
C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi ƒë√∫ng format:

**1) M√¨nh ƒëang th·∫•y g√¨**
- ...

**2) Kh·∫£ nƒÉng ƒëang g·∫∑p (2‚Äì4)**
- A: ...
- B: ...
- C: ...

**3) Em h·ªèi th√™m 1‚Äì2 c√¢u ƒë·ªÉ x√°c ƒë·ªãnh**
- C√¢u 1: ...
- C√¢u 2: ...

**4) M√¨nh coi/ki·ªÉm tra an to√†n t·∫°i ao**
- ...
""".strip()
            resp = self.llm.invoke([{"role": "system", "content": system}, {"role": "user", "content": user}])
            return _localize_text((resp.content or "").strip())

        if it == "analysis":
            compact = _render_compact(water_data, prediction)
            system = """
B·∫°n l√† tr·ª£ l√Ω PH√ÇN T√çCH m√¥i tr∆∞·ªùng nu√¥i t√¥m qu·∫£ng canh ·ªü C√† Mau, n√≥i ki·ªÉu mi·ªÅn T√¢y.
B·∫Øt bu·ªôc:
- CH·ªà ph√¢n t√≠ch hi·ªán tr·∫°ng d·ª±a tr√™n d·ªØ li·ªáu v√† k·∫øt qu·∫£ m√¥ h√¨nh.
- Tuy·ªát ƒë·ªëi KH√îNG ƒë∆∞a gi·∫£i ph√°p/khuy·∫øn ngh·ªã/k·∫ø ho·∫°ch/h∆∞·ªõng d·∫´n.
- Tr√°nh c√°c t·ª´/c·ª•m: x·ª≠ l√Ω, n√™n l√†m, khuy·∫øn ngh·ªã, ƒë·ªÅ xu·∫•t, h∆∞·ªõng d·∫´n, k·∫ø ho·∫°ch, li·ªÅu, d√πng, b·ªï sung, tƒÉng, gi·∫£m.
- N·∫øu thi·∫øu d·ªØ li·ªáu quan tr·ªçng, h·ªèi t·ªëi ƒëa 2 c√¢u ng·∫Øn.
""".strip()
            user = f"""
{compact}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi ƒë√∫ng format:

**1) ƒê√°nh gi√°**
- ...

**2) C√°c ƒëi·ªÉm ƒë·∫°t (t·ªëi ƒëa 5)**
- ...

**3) C√°c ƒëi·ªÉm l·ªách ng∆∞·ª°ng**
- t·ª´ng ch·ªâ s·ªë: (hi·ªán t·∫°i | chu·∫©n | h·ªá qu·∫£/r·ªßi ro)

**4) R·ªßi ro t·ªïng h·ª£p theo 4 task**
- ...
""".strip()
            resp = self.llm.invoke([{"role": "system", "content": system}, {"role": "user", "content": user}])
            return _localize_text((resp.content or "").strip())

        if it == "advice":
            compact = _render_compact(water_data, prediction)
            rag_snippet = ""
            if self.qa_chain is not None:
                rag_query = "T√≥m t·∫Øt t·ªëi ƒëa 6 g·∫°ch ƒë·∫ßu d√≤ng v·ªÅ x·ª≠ l√Ω Vibrio, DO th·∫•p, pH l·ªách, NO2/NH4 cao, qu·∫£n l√Ω t·∫£o trong nu√¥i t√¥m qu·∫£ng canh."
                try:
                    rag_resp = self.qa_chain.invoke({"query": rag_query})
                    rag_snippet = (rag_resp.get("result") or "").strip()
                except Exception:
                    rag_snippet = ""

            system = """
B·∫°n l√† tr·ª£ l√Ω T∆Ø V·∫§N nu√¥i t√¥m qu·∫£ng canh ·ªü C√† Mau, n√≥i ki·ªÉu mi·ªÅn T√¢y, d·ªÖ hi·ªÉu.
B·∫Øt bu·ªôc:
- B√°m s√°t d·ªØ li·ªáu ao + 4 task.
- N√≥i r√µ ch·ªâ s·ªë l·ªách ng∆∞·ª°ng v√† v√¨ sao nguy.
- G·∫°ch ƒë·∫ßu d√≤ng, ng·∫Øn, d·ªÖ l√†m theo.
- C√≥ ∆∞u ti√™n P1/P2/P3 v√† m·ªëc th·ªùi gian.
- Kh√¥ng khuy·∫øn kh√≠ch l·∫°m d·ª•ng kh√°ng sinh/h√≥a ch·∫•t.
""".strip()
            user = f"""
{compact}

Tham kh·∫£o t√†i li·ªáu (n·∫øu c√≥):
{rag_snippet if rag_snippet else "(kh√¥ng c√≥)"}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi ƒë√∫ng format:

**1) ƒê√°nh gi√° nhanh**
- ...

**2) V·∫•n ƒë·ªÅ ch√≠nh**
- t·ª´ng ch·ªâ s·ªë: (hi·ªán t·∫°i | chu·∫©n | v√¨ sao nguy)

**3) K·∫ø ho·∫°ch theo ∆∞u ti√™n**
- P1 (24h): ...
- P2 (3 ng√†y): ...
- P3 (1‚Äì2 tu·∫ßn): ...

**4) L∆∞u √Ω an to√†n sinh h·ªçc**
- ...
""".strip()
            resp = self.llm.invoke([{"role": "system", "content": system}, {"role": "user", "content": user}])
            return _localize_text((resp.content or "").strip())

        system = """
B·∫°n l√† tr·ª£ l√Ω k·ªπ thu·∫≠t nu√¥i t√¥m qu·∫£ng canh ·ªü C√† Mau, n√≥i ki·ªÉu mi·ªÅn T√¢y, d·ªÖ hi·ªÉu.
B·∫Øt bu·ªôc:
- Tr·∫£ l·ªùi ki·∫øn th·ª©c chung theo c√¢u h·ªèi (t·∫£o, pH, DO, Vibrio, m√¥i tr∆∞·ªùng...).
- Kh√¥ng b·∫Øt ng∆∞·ªùi d√πng ph·∫£i ‚Äúph√¢n t√≠ch/t∆∞ v·∫•n‚Äù n·∫øu h·ªç h·ªèi chung.
- N·∫øu c·∫ßn th√¥ng tin ƒë·ªÉ s√°t th·ª±c t·∫ø, h·ªèi t·ªëi ƒëa 2 c√¢u.
- Kh√¥ng khuy·∫øn kh√≠ch l·∫°m d·ª•ng kh√°ng sinh/h√≥a ch·∫•t.
""".strip()
        user = f"""
C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi g·ªçn, d·ªÖ hi·ªÉu, ƒë√∫ng gi·ªçng mi·ªÅn T√¢y. N·∫øu c√¢u h·ªèi ƒëang thi·∫øu th√¥ng tin ƒë·ªÉ k·∫øt lu·∫≠n ch·∫Øc, h·ªèi l·∫°i t·ªëi ƒëa 2 c√¢u.
""".strip()
        resp = self.llm.invoke([{"role": "system", "content": system}, {"role": "user", "content": user}])
        return _localize_text((resp.content or "").strip())
